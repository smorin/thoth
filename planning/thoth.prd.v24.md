# Product Requirements Document â€“ Thoth v2.4

---

## 1. Document Control

| Item | Value |
|------|-------|
| Author | System Design Team |
| Date | 03 Aug 2025 |
| Status | In Development |
| Target Release | v2.6 |
| Document Version | 26.0 |

### Changes in Version 26.0
- Updated version to v2.6 based on v2.5
- Integrated clarification mode directly into interactive mode
- Added Shift+Tab key binding to toggle between Edit Mode and Clarification Mode
- Implemented prompt refinement workflow within interactive session
- Added --clarify flag to start interactive mode in Clarification Mode
- Prompt interception and clarification in Clarification Mode before submission
- Support for multiple clarification rounds within same session
- Visual mode indicators and context-sensitive help text

### Changes in Version 25.0
- Updated version to v2.5 based on v2.4
- Implemented OpenAI provider with AsyncOpenAI client (Milestone 8 complete)
- Added response storage using dictionary pattern for concurrent operations
- Implemented timeout configuration with CLI override (--timeout flag with highest precedence)
- Added comprehensive error handling with retry logic using tenacity
- Implemented configurable temperature and max_tokens for OpenAI provider
- Created M8T test suite with 10 tests achieving 100% pass rate
- Enhanced Makefile with separate targets for main executable and test suite
- Added combined Makefile targets for full codebase operations
- Implemented UV-based tool execution for ruff and ty without installation
- Added comprehensive OpenAI provider documentation to README.md
- Provider configuration now supports model, timeout, temperature, and max_tokens settings

### Changes in Version 24.0
- Updated version to v2.4 based on v2.3
- Implemented clean architecture with class-based organization in single file
- Added ConfigManager for layered configuration with clear precedence hierarchy
- Created CommandHandler for unified command execution across interfaces
- Implemented ProviderRegistry for better provider management
- Added configuration validation and schema enforcement
- Improved separation of concerns while maintaining single-file distribution
- Configuration precedence: defaults < user < project < env vars < CLI < interactive

### Changes in Version 23.0
- Updated version to v2.3 based on v2.2
- Added interactive prompt mode with `-i` or `--interactive` flag
- Implemented bordered input box with multi-line support
- Added slash commands for dynamic option modification
- Added help text display above input box in dim color
- Support for placeholder text in input box (implementation-dependent)
- Added Unix line editing shortcuts (Ctrl+A, Ctrl+E, Ctrl+K)
- Single prompt per interactive session with automatic exit after submission
- Added model caching for OpenAI provider with automatic refresh after 1 week
- Implemented `--refresh-cache` flag to force refresh model lists
- Enhanced `--list` output to show cache age and status
- Added ModelCache class for managing cached model lists in ~/.thoth/model_cache/
- Added `--no-cache` flag to bypass model cache without updating it

### Changes in Version 22.0
- Updated version to v2.2 based on v2.1
- Enhanced `providers` command with `--list` flag to show available providers
- Added provider status display (configured/not configured)
- Added `--keys` flag to show API key configuration for each provider
- Changed CLI API key options to be provider-specific (e.g., `--api-key-openai` instead of generic `--api-key`)
- Providers automatically detected from registry
- Consistent use of `--` separator for subcommand options
- Added model information to metadata headers (F-114)
- Mock provider shows "None" as the model (F-115)
- Added prompt section to output files showing exact prompts sent to LLM (F-116)
- Added --no-metadata flag to disable metadata headers and prompt section (F-117)

### Changes in Version 21.0
- Updated version to v2.1 based on v2.0
- Added `providers` command to list available models from each provider
- OpenAI models fetched dynamically via API
- Perplexity models hardcoded as specified
- Implemented dynamic column width for model ID display to prevent truncation

### Changes in Version 20.0
- Updated version to v2.1 to reflect comprehensive feature additions
- Added new commands: update, clean, config, export, import
- Added advanced provider features from implementation plan
- Added multi-provider coordination features
- Added missing core features as new requirements
- Added --auto flag for mode chaining
- Added adaptive polling intervals
- Added operation lifecycle management
- Added shell completion support
- All features from implementation plan v4.0 incorporated

---

## 2. Executive Summary

Thoth is a command-line interface (CLI) tool that automates deep technical research using multiple LLM providers. **The primary use case is simple: just give it a prompt and get comprehensive research results in your current directory.** While Thoth supports advanced features like mode selection, project organization, and async operations, the default experience is optimized for immediate, zero-configuration research.

### Core Value Propositions
- **Instant research**: Just `thoth "your prompt"` â€“ no mode selection needed
- **Multi-provider intelligence**: Automatic parallel execution of OpenAI and Perplexity
- **Zero-configuration deployment**: Works immediately with API keys
- **Current directory output**: Results appear right where you are working
- **Advanced features when needed**: Full mode control, projects, and async operations available
- **Production-ready reliability**: Checkpoint/resume, graceful error handling, and operation persistence

---

## 3. Product Overview

### Vision
Create the simplest yet most powerful research tool where users can get comprehensive research results with a single command, while preserving advanced capabilities for power users.

### Target Users
- **Primary**: Anyone needing quick research results with minimal friction
- **Secondary**: 
  - Researchers requiring deep technical analysis
  - Developers needing comprehensive API documentation research
  - Analysts conducting multi-source investigations
  - Teams automating research workflows

### Key Features
- **Default deep research mode**: No need to specify mode for common use cases
- **Automatic file output**: Results saved to current directory by default
- **Smart defaults**: Sensible configuration out of the box
- **Progressive complexity**: Simple for basic use, powerful when needed
- **Multi-provider results**: Automatic parallel execution for comprehensive coverage
- **Long operation handling**: Graceful handling of 5-30+ minute research tasks

---

## 4. Glossary

| Term | Definition |
|------|------------|
| Default mode | When no mode is specified, uses a special 'default' mode that passes prompts directly to the LLM without any system prompt. Files created with this mode include 'default' in the filename pattern. NOTE: Quick mode (`thoth "prompt"`) uses "default" mode, NOT "deep_research" |
| Quick mode | Simplified invocation with just a prompt, using all defaults |
| Mode | Workflow phase (clarification, exploration, deep_research, thinking) with its own prompt template |
| Provider | LLM backend (openai, perplexity, mock) |
| Mock provider | Test provider that returns static responses WITHOUT requiring API keys (accepts any value as dummy key for testing) |
| Operation ID | Unique identifier for each research operation (format: research-YYYYMMDD-HHMMSS-xxxxxxxxxxxxxxxx) |
| Background mode | Asynchronous execution where job is submitted and CLI exits immediately |
| Ad-hoc mode | Default mode where files are saved to current working directory |
| Project mode | Mode where files are saved to `base_output_dir/project-name/` |
| Combined report | Synthesized report merging results from multiple providers (requires --combined flag) |
| Output file | File created in format: YYYY-MM-DD_HHMMSS_deep_research_<provider>_<slug>.md |
| Mode chaining | Automatic flow from one mode to another using --auto flag |
| Adaptive polling | Dynamic adjustment of status check intervals based on operation characteristics |
| Provider fallback | Automatic failover to alternate provider on failure |
| Model cache | Local storage of provider model lists to reduce API calls and improve performance. Stored in ~/.thoth/model_cache/ |
| Cache refresh | Process of updating cached model lists, either automatically (after 1 week) or manually via --refresh-cache flag |

---

## 5. Objectives

1. **Zero-friction research** â€“ just prompt and go
2. **One-command simplicity** with sensible defaults
3. **Current directory convenience** â€“ results appear where you work
4. **Progressive disclosure** â€“ advanced features available but not required
5. **Multi-provider by default** â€“ comprehensive results without configuration
6. **Async robustness** â€“ never hang; handle long operations gracefully
7. **Deterministic artifacts** â€“ predictable file naming and locations
8. **POSIX compatibility** â€“ run on macOS and Linux
9. **Testability** â€“ mock provider enables comprehensive testing without API keys

---

## 6. Out of Scope (v2.1)

- Webhooks for completion notifications
- Private data integration (MCP)
- Citation verification system
- Streaming token output display
- Concurrent multi-prompt execution
- Rich TUI with live visualizations
- Cloud storage integration
- Real-time collaboration features
- Web UI or API server mode
- Windows support
- Plugin system (deferred to future release)

---

## 7. Assumptions

- Python â‰¥ 3.11 installed
- Users provide provider API keys via environment variables or config
- Deep Research jobs can take 5â€“30 minutes
- Most users want deep research results in their current directory
- Users prefer simple commands over complex configuration
- File paths must work on POSIX systems (macOS/Linux)
- Network connectivity available for API calls
- Sufficient disk space for output artifacts
- Mock provider used for testing and development

---

## 8. Functional Requirements

### Core Requirements

| ID | Requirement | Priority | Test ID |
|----|-------------|----------|---------|
| F-01 | When no mode specified, use 'default' mode with no system prompt and include 'default' in filename | Must | T-MODE-01 |
| F-02 | Accept prompt as single positional argument: `thoth "prompt"` | Must | T-CLI-01 |
| F-03 | Save outputs to current directory by default | Must | T-OUT-01 |
| F-04 | Support full mode specification for advanced users | Must | T-MODE-02 |
| F-05 | Single config file `~/.thoth/config.toml` with all settings | Must | T-CFG-01 |
| F-06 | Built-in defaults overridden by config file, overridden by CLI args | Must | T-CFG-02 |
| F-07 | Create jobs in background mode; capture and return operation_id | Must | T-ASYNC-01 |
| F-08 | Poll job status every n seconds (configurable); default 30s | Must | T-ASYNC-02 |
| F-09 | Abort after configurable timeout; default 30 minutes | Must | T-ASYNC-03 |
| F-10 | `--async` / `-A` submits job and exits immediately with operation_id | Must | T-ASYNC-04 |
| F-11 | `--resume` / `-R` resumes an existing operation by ID | Must | T-ASYNC-05 |
| F-12 | `list` command shows all active/recent operations | Must | T-CMD-01 |
| F-13 | `status` command shows detailed status of specific operation | Must | T-CMD-02 |
| F-14 | `init` command runs interactive setup wizard | Must | T-CMD-03 |
| F-15 | Dual-provider execution for deep_research mode by default | Must | T-PROV-01 |
| F-16 | Files created by default; filename pattern: `YYYY-MM-DD_HHMMSS_<mode>_<provider>_<slug>.md` | Must | T-OUT-02 |
| F-17 | Show clear progress during research execution | Must | T-UX-01 |
| F-18 | Display output file locations upon completion | Must | T-UX-02 |
| F-19 | Mask API keys in all output (logs, errors, debug) - keys must be replaced with pattern like sk-*** in stdout/stderr | Must | T-SEC-01 |
| F-20 | Generate combined report from multi-provider results with --combined flag | Must | T-OUT-03 |
| F-21 | Support individual provider files by default (no combined report) | Must | T-OUT-04 |
| F-22 | Clear error messages for missing API keys | Must | T-ERR-01 |
| F-23 | Automatic retry on transient network errors | Must | T-NET-01 |
| F-24 | Path expansion for all file paths in config (handle ~) | Must | T-CFG-03 |
| F-25 | Environment variable substitution in config file | Must | T-CFG-04 |

### Additional Quick Mode Requirements

| ID | Requirement | Priority | Test ID |
|----|-------------|----------|---------|
| F-26 | `thoth "prompt"` executes deep research in current directory | Must | T-QUICK-01 |
| F-27 | Show simple progress indicator for quick mode (includes operation ID in verbose mode) | Must | T-QUICK-02 |
| F-28 | Display final output filenames prominently | Must | T-QUICK-03 |
| F-29 | Minimal output during execution unless --verbose | Must | T-QUICK-04 |
| F-30 | Help text shows quick mode as primary usage pattern | Must | T-HELP-01 |
| F-31 | Default mode must pass user prompt directly to LLM without any system prompt modifications | Must | T-MODE-03 |

### Testing and Error Handling Requirements

| ID | Requirement | Priority | Test ID |
|----|-------------|----------|---------|
| F-32 | Mock provider must work without any API keys for testing | Must | T-MOCK-01 |
| F-33 | All error messages must go to stderr, not stdout (Rich console UI to stdout is correct) | Must | T-ERR-02 |
| F-34 | Mode and provider validation must happen before API key checks | Must | T-VAL-01 |
| F-35 | Commands must return proper exit codes: 0=success, 1=general error, 2=usage error | Must | T-EXIT-01 |
| F-36 | Output directories must be created automatically if they don't exist | Must | T-OUT-05 |
| F-37 | Init command must work with custom config directories via XDG_CONFIG_HOME | Must | T-CFG-05 |
| F-38 | Implement --quiet flag to suppress non-essential output | Must | T-UX-03 |
| F-39 | Support -P as short form for --provider flag | Must | T-CLI-03 |
| F-40 | Implement --config flag for custom config file location | Must | T-CFG-06 |

### New Command Requirements (v2.1)

| ID | Requirement | Priority | Test ID |
|----|-------------|----------|---------|
| F-41 | Implement `update` command to fix stale operation statuses | Must | T-CMD-04 |
| F-42 | Implement `clean` command with filtering options for checkpoint management | Must | T-CMD-05 |
| F-43 | Implement `config` command for configuration management | Must | T-CMD-06 |
| F-44 | Implement `export` command to export research results | Must | T-CMD-07 |
| F-45 | Implement `import` command to import research data | Must | T-CMD-08 |
| F-46 | Add --force flag support where applicable | Must | T-CLI-04 |
| F-47 | Add --dry-run flag for preview operations | Must | T-CLI-05 |

### Advanced Mode Requirements (v2.1)

| ID | Requirement | Priority | Test ID |
|----|-------------|----------|---------|
| F-48 | Implement --auto flag for automatic mode chaining | Must | T-MODE-04 |
| F-49 | Support reading from previous output files automatically | Must | T-MODE-05 |
| F-50 | Implement symlink path resolution | Must | T-FILE-01 |
| F-51 | Add max file size limits for input files | Must | T-FILE-02 |
| F-52 | Create operation metadata tracking | Must | T-META-01 |

### Provider Enhancement Requirements (v2.1)

| ID | Requirement | Priority | Test ID |
|----|-------------|----------|---------|
| F-53 | Implement retry logic with exponential backoff | Must | T-NET-02 |
| F-54 | Add streaming response support for providers | Should | T-PROV-02 |
| F-55 | Implement token counting and display | Should | T-PROV-03 |
| F-56 | Add cost estimation and tracking | Should | T-PROV-04 |
| F-57 | Support temperature control from config | Should | T-PROV-05 |
| F-58 | Add response caching mechanism | Should | T-CACHE-01 |
| F-59 | Implement rate limit handling with backoff | Must | T-NET-03 |

### Multi-Provider Coordination (v2.1)

| ID | Requirement | Priority | Test ID |
|----|-------------|----------|---------|
| F-60 | Implement provider fallback chains | Must | T-MULTI-01 |
| F-61 | Add cost optimization routing | Should | T-MULTI-02 |
| F-62 | Create quality-based provider selection | Should | T-MULTI-03 |
| F-63 | Implement provider health checks | Must | T-MULTI-04 |
| F-64 | Add unified error handling across providers | Must | T-MULTI-05 |
| F-65 | Implement cross-provider deduplication | Should | T-MULTI-06 |

### Progress and UX Enhancements (v2.1)

| ID | Requirement | Priority | Test ID |
|----|-------------|----------|---------|
| F-66 | Implement adaptive polling intervals | Should | T-UX-05 |
| F-67 | Add operation lifecycle management with states: queuedâ†’runningâ†’completed/failed/cancelled, with proper transitions | Must | T-ASYNC-06 |
| F-68 | Create first-time setup flow improvements | Should | T-UX-06 |
| F-69 | Add helpful tips for new users | Should | T-UX-07 |
| F-70 | Implement shell completion support | Should | T-CLI-06 |

### Configuration Enhancements (v2.1)

| ID | Requirement | Priority | Test ID |
|----|-------------|----------|---------|
| F-71 | Add config validation command | Must | T-CFG-07 |
| F-72 | Support per-project configuration | Should | T-CFG-08 |
| F-73 | Implement config migration for version updates | Must | T-CFG-09 |
| F-74 | Add config export/import functionality | Should | T-CFG-10 |
| F-75 | Support environment-specific configs | Should | T-CFG-11 |

### Clean Command Features (v2.1)

| ID | Requirement | Priority | Test ID |
|----|-------------|----------|---------|
| F-76 | Support --in-progress, --completed, --failed filters | Must | T-CLEAN-01 |
| F-77 | Add --days filter for age-based cleanup | Must | T-CLEAN-02 |
| F-78 | Implement --pattern filter for pattern matching | Should | T-CLEAN-03 |
| F-79 | Add --keep-recent option to preserve N most recent | Must | T-CLEAN-04 |
| F-80 | Detect and clean orphaned output files | Should | T-CLEAN-05 |

### Critical Infrastructure Requirements (v2.1)

| ID | Requirement | Priority | Test ID |
|----|-------------|----------|---------|
| F-81 | Implement graceful shutdown on Ctrl-C with checkpoint save | Must | T-SIG-01 |
| F-82 | Implement checkpoint corruption detection and recovery | Must | T-ASYNC-07 |

### OpenAI Provider Requirements (v2.5 - IMPLEMENTED)

| ID | Requirement | Priority | Test ID | Status |
|----|-------------|----------|---------|--------|
| F-83 | OpenAI streaming response support | Must | M8T-06 | âœ“ Implemented |
| F-84 | OpenAI token counting and display | Must | M8T-07 | âœ“ Implemented |
| F-85 | OpenAI cost estimation and tracking | Should | T-OAI-03 | Partial |
| F-86 | OpenAI partial response saving on failure | Must | M8T-08 | âœ“ Implemented |
| F-87 | OpenAI model selection from config | Must | M8T-01 | âœ“ Implemented |
| F-88 | OpenAI timeout configuration with CLI override | Must | M8T-04 | âœ“ Implemented |
| F-89 | OpenAI temperature configuration | Must | M8T-01 | âœ“ Implemented |
| F-90 | OpenAI max_tokens configuration | Must | M8T-01 | âœ“ Implemented |
| F-91 | OpenAI error handling with retry logic | Must | M8T-03, M8T-08, M8T-10 | âœ“ Implemented |
| F-92 | OpenAI response storage for concurrent operations | Must | M8T-05 | âœ“ Implemented |

### Perplexity Provider Requirements (v2.1)

| ID | Requirement | Priority | Test ID |
|----|-------------|----------|---------|
| F-93 | Perplexity citation extraction and formatting | Must | T-PPLX-01 |
| F-94 | Perplexity web search mode support | Must | T-PPLX-02 |
| F-95 | Perplexity academic search mode | Should | T-PPLX-03 |
| F-96 | Perplexity real-time data queries | Must | T-PPLX-04 |
| F-97 | Perplexity search depth control | Should | T-PPLX-05 |
| F-98 | Perplexity source filtering | Should | T-PPLX-06 |
| F-99 | Perplexity source reliability scores | Should | T-PPLX-07 |

### Advanced Multi-Provider Requirements (v2.1)

| ID | Requirement | Priority | Test ID |
|----|-------------|----------|---------|
| F-100 | Provider load balancing | Should | T-MULTI-07 |
| F-101 | Circuit breaker pattern for provider failures | Must | T-MULTI-08 |
| F-102 | Dynamic provider selection based on prompt type | Should | T-MULTI-09 |
| F-103 | Partial result handling across providers | Must | T-MULTI-10 |
| F-104 | Provider capability matching | Should | T-MULTI-11 |
| F-105 | Cross-provider performance monitoring | Should | T-MULTI-12 |

### Provider Discovery Requirements (v2.1)

| ID | Requirement | Priority | Test ID |
|----|-------------|----------|---------|
| F-106 | Implement `providers` command to list available models | Must | T-PROV-06 |
| F-107 | Fetch OpenAI models dynamically via API endpoint and cache locally for 1 week | Must | T-PROV-07 |
| F-108 | Return hardcoded model list for Perplexity provider | Must | T-PROV-08 |
| F-109 | Support --models flag to display available models | Must | T-PROV-09 |
| F-110 | Support filtering by provider with --provider flag | Must | T-PROV-10 |
| F-111 | Format model list output using Rich tables with dynamic column width | Should | T-PROV-11 |
| F-112 | Handle API errors gracefully when fetching models | Must | T-PROV-12 |
| F-113 | Show list of available providers with cache status when `thoth providers -- --list` is run | Must | T-PROV-13 |
| F-114 | Automatically detect available providers from the provider registry | Must | T-PROV-14 |
| F-115 | Display provider status (configured/not configured) based on API key presence | Must | T-PROV-15 |
| F-116 | Support both `--list` and `--models` flags after `--` separator | Must | T-PROV-16 |
| F-117 | Update help text to show both provider listing and model listing options | Must | T-PROV-17 |
| F-118 | Show API key configuration with --keys flag displaying env vars and provider-specific CLI args | Must | T-PROV-18 |
| F-119 | Implement model caching for OpenAI provider with 1-week expiration | Must | T-CACHE-02 |
| F-120 | Support --refresh-cache flag to force model list refresh | Must | T-CACHE-03 |
| F-121 | Display cache age and status in provider list output | Must | T-CACHE-04 |
| F-122 | Auto-refresh cache when older than 1 week | Must | T-CACHE-05 |
| F-123 | Store model cache in ~/.thoth/model_cache/ directory | Must | T-CACHE-06 |
| F-124 | Support --no-cache flag to bypass model cache without updating it | Must | T-CACHE-07 |

### Output Format Requirements (v2.2)

| ID | Requirement | Priority | Test ID |
|----|-------------|----------|---------|
| F-125 | Metadata headers must include the model used by each provider | Must | T-OUT-06 |
| F-126 | Mock provider must show "None" as the model in metadata | Must | T-OUT-07 |
| F-127 | Output files must include the prompt section showing system prompt and user prompt | Must | T-OUT-08 |
| F-128 | Support --no-metadata flag to disable metadata headers and prompt section in output files | Must | T-OUT-09 |

### Interactive Mode Requirements (v2.3)

| ID | Requirement | Priority | Test ID |
|----|-------------|----------|---------|
| F-129 | Support `-i` or `--interactive` flag to enter interactive prompt mode | Must | T-INT-01 |
| F-130 | Display bordered input box with configurable width (default 80% terminal width) | Must | T-INT-02 |
| F-131 | Support multi-line input with Shift+Enter for new lines, Enter to submit | Must | T-INT-03 |
| F-132 | Display prompt character ">" at beginning of each input line | Must | T-INT-04 |
| F-133 | Support slash commands for dynamic option modification | Must | T-INT-05 |
| F-134 | Implement `/help` command to show available slash commands | Must | T-INT-06 |
| F-135 | Implement `/exit` and `/quit` commands to exit without submitting | Must | T-INT-07 |
| F-136 | Implement `/mode <mode>` command to change research mode with auto-completion | Must | T-INT-08 |
| F-137 | Implement `/provider <provider>` command to set provider | Must | T-INT-09 |
| F-138 | Implement `/async` toggle command for async submission | Must | T-INT-10 |
| F-139 | Support standard Unix line editing shortcuts (Ctrl+A, Ctrl+E, Ctrl+K) | Must | T-INT-11 |
| F-140 | Execute prompt with same behavior as non-interactive mode after submission | Must | T-INT-12 |
| F-141 | Implement `/status` command to check operation status | Must | T-INT-13 |
| F-142 | Display help text above input box in dimmed/light color with key commands | Must | T-INT-14 |

### Architecture and Code Organization Requirements (v2.4)

| ID | Requirement | Priority | Test ID |
|----|-------------|----------|---------|
| F-143 | Implement layered configuration with clear precedence hierarchy (defaults < user < project < env < CLI < interactive) | Must | T-ARCH-01 |
| F-144 | Create ConfigManager class for unified configuration handling | Must | T-ARCH-02 |
| F-145 | Implement CommandHandler class for unified command execution across interfaces | Must | T-ARCH-03 |
| F-146 | Create ProviderRegistry for dynamic provider management | Must | T-ARCH-04 |
| F-147 | Add configuration schema validation at load time | Must | T-ARCH-05 |
| F-148 | Support project-level configuration file (./thoth.toml or ./.thoth/config.toml) | Should | T-ARCH-06 |
| F-149 | Implement configuration merging with deep merge support | Must | T-ARCH-07 |
| F-150 | Add dot notation config access (e.g., config.get('providers.openai.model')) | Should | T-ARCH-08 |
| F-151 | Maintain single-file distribution while improving internal organization | Must | T-ARCH-09 |

### Development Infrastructure Requirements (v2.5 - IMPLEMENTED)

| ID | Requirement | Priority | Test ID | Status |
|----|-------------|----------|---------|--------|
| F-152 | Separate Makefile targets for main executable (lint, format, typecheck, check, fix) | Must | - | âœ“ Implemented |
| F-153 | Separate Makefile targets for test suite (test-lint, test-format, test-typecheck, test-check, test-fix) | Must | - | âœ“ Implemented |
| F-154 | Combined Makefile targets for full codebase (lint-all, format-all, check-all, fix-all) | Must | - | âœ“ Implemented |
| F-155 | UV-based tool execution without installation requirement | Must | - | âœ“ Implemented |
| F-156 | Ruff integration for linting and formatting via UV | Must | - | âœ“ Implemented |
| F-157 | Ty integration for type checking via UV | Must | - | âœ“ Implemented |
| F-158 | Independent verification of main code vs test code | Must | - | âœ“ Implemented |
| F-159 | Comprehensive help target showing all available commands | Must | - | âœ“ Implemented |

### Interactive Clarification Mode Requirements (v2.6)

| ID | Requirement | Priority | Test ID |
|----|-------------|----------|---------|
| F-160 | Support Shift+Tab to toggle between Edit Mode and Clarification Mode in interactive mode | Must | T-CLAR-01 |
| F-161 | Display current mode (Edit Mode/Clarification Mode) in interactive UI | Must | T-CLAR-02 |
| F-162 | In Clarification Mode, intercept prompt submission for refinement | Must | T-CLAR-03 |
| F-163 | Send prompt to clarification prompt for improvement suggestions | Must | T-CLAR-04 |
| F-164 | Display clarification questions/suggestions in interactive box | Must | T-CLAR-05 |
| F-165 | Allow user to edit refined prompt before final submission | Must | T-CLAR-06 |
| F-166 | Support multiple clarification rounds within same session | Must | T-CLAR-07 |
| F-167 | Add --clarify flag to force Clarification Mode on startup | Should | T-CLAR-08 |
| F-168 | Show mode toggle instructions below input box | Must | T-CLAR-09 |
| F-169 | Preserve original prompt when switching modes | Must | T-CLAR-10 |
| F-170 | Support Enter to accept clarification, Shift+Tab to return to edit | Must | T-CLAR-11 |

---

## 9. Non-Functional Requirements

| ID | Requirement | Test ID |
|----|-------------|---------|
| N-01 | First result visible within 30 seconds | T-PERF-01 |
| N-02 | Tool runs on POSIX systems (macOS and Linux) | T-PLAT-01 |
| N-03 | Graceful exit on interrupt (Ctrl-C) with checkpoint save | T-SIG-01 |
| N-04 | Startup time < 100ms with cached dependencies | T-PERF-02 |
| N-05 | Clear progress indication during long operations | T-UX-04 |
| N-06 | Memory usage < 200MB typical, < 500MB peak | T-PERF-03 |
| N-07 | Operation ID collision probability < 0.0001% | T-ID-01 |
| N-08 | Simple error messages for common issues | T-ERR-03 |
| N-09 | All errors to stderr for proper shell scripting | T-ERR-04 |
| N-10 | Exit codes follow POSIX conventions | T-EXIT-02 |

---

## 10. Command-Line Interface

### 10.1 Command Structure

```bash
# PRIMARY USAGE - Quick Mode
thoth "PROMPT"                   # Deep research with output to current directory

# INTERACTIVE MODE - Visual Prompt Input
thoth -i                         # Enter interactive mode (Edit Mode)
thoth --interactive              # Same as above
thoth -i --clarify              # Start in Clarification Mode

# ADVANCED USAGE - Full Control  
thoth MODE PROMPT [OPTIONS]      # Specify mode and options
thoth [COMMAND] [OPTIONS]        # Run specific commands

Commands:
  (default)     Run research (uses 'default' mode when no mode specified, NOT deep_research)
  init          Initialize configuration with setup wizard
  status        Check status of specific operation
  list          List all active/recent operations
  update        Fix stale operation statuses
  clean         Clean up old checkpoints and files
  config        Manage configuration
  export        Export research results
  import        Import research data
  providers     List available models from each provider
  help          Show help for commands

Interactive Mode Commands:
  /help         Show available slash commands
  /mode <mode>  Set research mode (with auto-completion)
  /provider <p> Set provider (openai, perplexity, mock)
  /async        Toggle async submission mode
  /status       Check operation status
  /exit, /quit  Exit without submitting prompt

Interactive Mode Controls:
  Shift+Tab     Toggle between Edit Mode and Clarification Mode
  Enter         Submit (in Edit Mode) or Accept clarification (in Clarification Mode)
  Shift+Enter   New line (multi-line input)
  Ctrl+A/E/K    Standard Unix line editing
```

### 10.2 Usage Examples

#### Quick Mode (Primary Use Case)

```bash
# SIMPLEST USAGE - just provide a prompt (no system prompt added)
thoth "impact of quantum computing on cryptography"
# This sends your exact prompt to the LLM without modification
# Creates in current directory:
#   ./2024-08-03_143022_default_openai_impact-of-quantum-computing.md
#   ./2024-08-03_143022_default_perplexity_impact-of-quantum-computing.md  

# With combined report (requires flag)
thoth "impact of quantum computing on cryptography" --combined
# Also creates:
#   ./2024-08-03_143022_default_combined_impact-of-quantum-computing.md

# More quick examples
thoth "best practices for API design"
thoth "comparison of React vs Vue frameworks"
thoth "how does TCP congestion control work"

# Quick mode with single provider
thoth "kubernetes networking explained" --provider openai
thoth "kubernetes networking explained" -P openai  # Short form

# Testing with mock provider (no API key needed)
thoth "test prompt" --provider mock
thoth "test prompt" -P mock  # Short form
```

#### Interactive Mode Examples

```bash
# Enter interactive mode
thoth -i
# or
thoth --interactive

# Interactive session example:
$ thoth -i

[dim]Enter prompt â€¢ Shift+Enter: new line â€¢ Enter: submit â€¢ /help: commands[/dim]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ > /mode deep_research                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[green]Mode set to: deep_research[/green]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ > What are the security implications of                            â”‚
â”‚   quantum computing on current encryption methods?                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[Submits prompt and exits to normal processing]

# Interactive mode with provider change
$ thoth -i
> /provider openai
[green]Provider set to: openai[/green]
> /async
[green]Async mode: enabled[/green]
> How does DNS work?
[Submits with openai provider in async mode]
```

#### Advanced Mode Examples

```bash
# Specify a different mode
thoth thinking "quick analysis of JSON vs YAML"
thoth clarification "what are the implications of quantum computing"
thoth exploration "modern web authentication methods"

# Project mode - organize outputs
thoth "quantum cryptography" --project quantum_research
# Creates: ./research-outputs/quantum_research/...

# Async submission for long research
thoth "comprehensive analysis of distributed systems" --async
# Output:
# Research submitted
# Operation ID: research-20240803-143022-a1b2c3d4e5f6g7h8
# Check later with: thoth status research-20240803-143022-a1b2c3d4e5f6g7h8

# Mode chaining workflow with --auto
thoth clarification "building scalable microservices"
thoth exploration --auto  # Uses previous output automatically
thoth deep_research --auto  # Full research based on exploration

# Read prompt from file
thoth --prompt-file ./complex_research_prompt.txt

# Pipe prompt from another command
echo "analyze security implications of WebAssembly" | thoth --prompt-file -

# Quiet mode for minimal output
thoth "database optimization techniques" -Q

# Custom config file
thoth "machine learning trends" --config ~/projects/ml/thoth-config.toml
```

#### New Command Examples (v2.1)

```bash
# Update stale operations
thoth update                     # Update all stale operations
thoth update --dry-run          # Preview what would be updated

# Clean old checkpoints
thoth clean --days 30           # Remove operations older than 30 days
thoth clean --failed            # Remove only failed operations
thoth clean --keep-recent 10    # Keep 10 most recent operations
thoth clean --pattern "test*"   # Remove operations matching pattern

# List with filters
thoth list --in-progress        # Show only active operations
thoth list --completed          # Show only completed operations
thoth list --days 7             # Show operations from last 7 days

# Configuration management
thoth config validate           # Validate current configuration
thoth config export > backup.toml  # Export configuration
thoth config import backup.toml    # Import configuration

# Export/Import results
thoth export research-20240803-143022-xxx --format json
thoth import research-backup.json

# List available models
thoth providers --models                      # List all models for all providers
thoth providers --models --provider openai    # List OpenAI models only
thoth providers --models -P perplexity        # List Perplexity models only

# Model cache management
thoth providers -- --list                     # Show providers with cache status
thoth providers -- --models --refresh-cache   # Force refresh model cache
thoth providers -- --models --provider openai --refresh-cache  # Refresh specific provider
thoth providers -- --models --no-cache        # Bypass cache completely without updating it
```

### 10.3 Options Reference

| Long | Short | Type | Description |
|------|-------|------|-------------|
| --interactive | -i | flag | Enter interactive prompt mode with visual input box |
| --clarify | | flag | Start interactive mode in Clarification Mode (use with -i) |
| --mode | -m | TEXT | Research mode (defaults to 'default' when not specified) |
| --prompt | -q | TEXT | Research prompt (alternative to positional) |
| --prompt-file | -Q | PATH | Read prompt from file (use '-' for stdin) |
| --async | -A | flag | Submit and exit immediately |
| --resume | -R | ID | Resume existing operation by ID |
| --project | -p | TEXT | Project name for output organization |
| --output-dir | -o | PATH | Override output directory |
| --provider | -P | TEXT | Use single provider: openai, perplexity, or mock |
| --combined | | flag | Generate combined report from multiple providers |
| --quiet | -Q | flag | Minimal output during execution |
| --verbose | -v | flag | Enable detailed logging |
| --no-metadata | | flag | Disable metadata headers and prompt section in output files |
| --help | -h | flag | Show help and exit |
| --config | -c | PATH | Read config from this file or dir |
| --auto | | flag | Use previous output automatically (mode chaining) |
| --force | -f | flag | Force operation without confirmation |
| --dry-run | | flag | Preview operation without executing |
| --refresh-cache | | flag | Force refresh of cached model lists (providers command) |
| --no-cache | | flag | Bypass model cache without updating it (providers command) |

### 10.4 Commands Reference

| Command | Description | Example |
|---------|-------------|---------|  
| (default) | Run research with prompt | `thoth "your research prompt"` |
| init | Setup wizard for API keys | `thoth init` |
| status ID | Show operation details | `thoth status research-20240803-143022-xxx` |
| list | Show recent operations | `thoth list` |
| update | Fix stale operation statuses | `thoth update --dry-run` |
| clean | Clean up old checkpoints | `thoth clean --days 30` |
| config | Manage configuration | `thoth config validate` |
| export | Export research results | `thoth export operation-id` |
| import | Import research data | `thoth import file.json` |
| providers | List available models | `thoth providers --models` |

### 10.5 Exit Codes

| Code | Meaning | Example |
|------|---------|---------|
| 0 | Success | Research completed successfully |
| 1 | General error | API key missing, network error, etc. |
| 2 | Usage error | Invalid command, missing required arguments |

### 10.6 Help Text Structure

```
Thoth - AI-Powered Research Assistant

USAGE:
    thoth "PROMPT"                   # Quick research (recommended)
    thoth MODE PROMPT [OPTIONS]      # Advanced usage
    thoth COMMAND [OPTIONS]          # Run commands

QUICK START:
    thoth "impact of quantum computing"
    thoth "best practices for REST APIs"
    
EXAMPLES:
    # Simple research (saves to current directory)
    thoth "how does blockchain consensus work"
    
    # Research with single provider
    thoth "machine learning optimization" --provider openai
    thoth "machine learning optimization" -P openai
    
    # Test with mock provider (no API key needed)
    thoth "test prompt" --provider mock
    thoth "test query" -P mock
    
    # Async for long research
    thoth "comprehensive review of database architectures" --async
    
    # Generate combined report
    thoth "cloud architecture patterns" --combined
    
    # Clean old operations
    thoth clean --days 30

COMMANDS:
    init      Setup API keys and configuration
    status    Check research operation status  
    list      List recent research operations
    update    Fix stale operation statuses
    clean     Clean up old checkpoints
    config    Manage configuration

OPTIONS:
    -P, --provider    Use specific provider (openai/perplexity/mock)
    -A, --async       Submit and exit (check status later)
    -p, --project     Organize outputs in project directory
    -v, --verbose     Show detailed progress
    -h, --help        Show full help
    -Q, --quiet       Minimal output during execution
    --combined        Generate combined report from providers
    --auto            Use previous output automatically
    -c, --config      Use custom config file

Run 'thoth --help' for complete options and advanced usage.
```

---

## 11. User Experience

### 11.1 Quick Mode Experience

```bash
$ thoth "explain how DNS resolution works"

Researching: explain how DNS resolution works
Mode: default | Providers: OpenAI + Perplexity

Progress: [00:02:15] Next check in 15s, timeout in 27:45
â ¹ OpenAI: Analyzing topic...
â ¸ Perplexity: Searching sources...
Progress: [00:05:30] Next check in 30s, timeout in 24:30
â ¼ OpenAI: Deep research in progress...
â ´ Perplexity: Analyzing 12 sources...
âœ“ Perplexity: Complete
Progress: [00:08:15] Next check in 30s, timeout in 21:45
â ¦ OpenAI: Synthesizing findings...
âœ“ OpenAI: Complete

Research completed in 8m 32s

Files created:
  â€¢ 2024-08-03_143022_deep_research_openai_explain-how-dns-resolution.md
  â€¢ 2024-08-03_143022_deep_research_perplexity_explain-how-dns-resolution.md  

To generate a combined report, run with --combined flag
```

### 11.2 First-Time User Experience

```bash
$ thoth "what is quantum computing"

âš ï¸  No API keys found. Let's set them up:

? Enter OpenAI API key (or press Enter to use $OPENAI_API_KEY): sk-...
? Enter Perplexity API key (or press Enter to use $PERPLEXITY_API_KEY): pplx-...

âœ“ Configuration saved to ~/.thoth/config.toml

ğŸ’¡ Tips for new users:
  â€¢ Use --provider mock for testing without API keys
  â€¢ Add --combined to merge results from multiple providers
  â€¢ Use --async for long-running research tasks

Starting research: what is quantum computing
[... continues with normal research flow ...]
```

### 11.3 Mode Chaining Experience (v2.1)

```bash
$ thoth clarification "building microservices architecture"

Clarifying: building microservices architecture
Mode: clarification | Provider: OpenAI

âœ“ Clarification complete

File created:
  â€¢ 2024-08-03_143022_clarification_openai_building-microservices.md

$ thoth exploration --auto

Using previous output: 2024-08-03_143022_clarification_openai_building-microservices.md
Mode: exploration | Providers: OpenAI + Perplexity

[... exploration continues ...]

$ thoth deep_research --auto

Using previous output: 2024-08-03_143022_exploration_combined_building-microservices.md
Mode: deep_research | Providers: OpenAI + Perplexity

[... deep research continues ...]
```

### 11.4 Clean Command Experience (v2.1)

```bash
$ thoth clean --days 30 --dry-run

Analyzing checkpoints...

Would remove:
  â€¢ 15 operations older than 30 days
  â€¢ 42 associated output files
  â€¢ Total space to be freed: 128 MB

Operations to remove:
  - research-20240703-090122-abc... (completed, 45 days old)
  - research-20240705-143022-def... (failed, 43 days old)
  - ... (13 more)

Run without --dry-run to execute cleanup

$ thoth clean --days 30

âš ï¸  This will remove 15 operations and 42 files (128 MB)
Continue? [y/N]: y

Cleaning up...
âœ“ Removed 15 operations
âœ“ Removed 42 output files
âœ“ Freed 128 MB of disk space
```

### 11.5 Providers Command Experience (v2.2)

```bash
$ thoth providers -- --list

Available Providers:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Provider    â”‚ Status   â”‚ Description             â”‚ Model Cache                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ openai      â”‚ âœ“ Ready  â”‚ OpenAI GPT models       â”‚ 3 days old (refresh in 4 days) â”‚
â”‚ perplexity  â”‚ âœ— No key â”‚ Perplexity search AI    â”‚ N/A                          â”‚
â”‚ mock        â”‚ âœ“ Ready  â”‚ Mock provider for tests â”‚ N/A                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

To see available models, use: thoth providers -- --models
To refresh model cache, use: thoth providers -- --models --refresh-cache

$ thoth providers -- --models

Fetching available models...

OpenAI Models:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model ID                â”‚ Created      â”‚ Owned By    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ gpt-4-turbo-preview     â”‚ 2024-01-25   â”‚ openai      â”‚
â”‚ gpt-4o                  â”‚ 2024-05-13   â”‚ openai      â”‚
â”‚ gpt-4o-mini             â”‚ 2024-07-18   â”‚ openai      â”‚
â”‚ gpt-3.5-turbo           â”‚ 2022-12-01   â”‚ openai      â”‚
â”‚ o1-preview              â”‚ 2024-09-12   â”‚ openai      â”‚
â”‚ o1-mini                 â”‚ 2024-09-12   â”‚ openai      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Perplexity Models:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model ID                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ sonar-deep-research     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Mock Models:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model ID                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ mock-model-v1           â”‚
â”‚ mock-model-v2           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

$ thoth providers -- --models --provider openai

OpenAI Models:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model ID                â”‚ Created      â”‚ Owned By    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ gpt-4-turbo-preview     â”‚ 2024-01-25   â”‚ openai      â”‚
â”‚ gpt-4o                  â”‚ 2024-05-13   â”‚ openai      â”‚
â”‚ gpt-4o-mini             â”‚ 2024-07-18   â”‚ openai      â”‚
â”‚ gpt-3.5-turbo           â”‚ 2022-12-01   â”‚ openai      â”‚
â”‚ o1-preview              â”‚ 2024-09-12   â”‚ openai      â”‚
â”‚ o1-mini                 â”‚ 2024-09-12   â”‚ openai      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

$ thoth providers -- --keys

                Provider API Key Configuration                 
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Provider      â”‚ Environment Variable   â”‚ CLI Argument      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ openai        â”‚ OPENAI_API_KEY         â”‚ --api-key-openai  â”‚
â”‚ perplexity    â”‚ PERPLEXITY_API_KEY     â”‚ --api-key-perplexity â”‚
â”‚ mock          â”‚ MOCK_API_KEY           â”‚ --api-key-mock    â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Examples:
  # Set via environment variable
  $ export OPENAI_API_KEY="your-key-here"

  # Set via command line for single provider
  $ thoth "prompt" --api-key-openai "your-key-here" --provider openai

  # Set multiple API keys for multi-provider modes
  $ thoth deep_research "prompt" --api-key-openai "sk-..." --api-key-perplexity "pplx-..."

$ thoth providers -- --models --refresh-cache

Fetching available models (refreshing cache)...

OpenAI Models:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model ID                â”‚ Created      â”‚ Owned By    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ gpt-4-turbo-preview     â”‚ 2024-01-25   â”‚ openai      â”‚
â”‚ gpt-4o                  â”‚ 2024-05-13   â”‚ openai      â”‚
â”‚ gpt-4o-mini             â”‚ 2024-07-18   â”‚ openai      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[Cache refreshed and saved locally]
```

### 11.6 Progress Display Details

The progress display implementation includes:
- **Elapsed time**: `[HH:MM:SS]` - Currently implemented
- **Next check time**: `Next check in Xs` - Partially implemented for async operations
- **Timeout countdown**: `timeout in MM:SS` - Fully implemented in examples (see AUDIT-005)
- **Operation ID**: Shown in verbose mode output
- **Adaptive intervals**: Check frequency adjusts based on operation duration

Note: All progress display features shown in examples are now fully implemented as of v2.1.

### 11.7 Interactive Clarification Mode Experience (v2.6)

```bash
$ thoth -i

[dim]Edit Mode â€¢ Shift+Tab: switch to Clarification Mode â€¢ Enter: submit â€¢ /help: commands[/dim]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ > help with database performance                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[User presses Shift+Tab]

[dim]Clarification Mode â€¢ Shift+Tab: switch to Edit Mode â€¢ Enter: clarify[/dim]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ > help with database performance                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[User presses Enter - prompt sent for clarification]

[dim]Clarification Mode â€¢ Review suggestions â€¢ Enter: accept â€¢ Shift+Tab: edit[/dim]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Your prompt could be more specific. Consider:                      â”‚
â”‚                                                                     â”‚
â”‚ 1. PostgreSQL query optimization for slow SELECT statements with   â”‚
â”‚    complex JOINs on large tables (100GB+)                         â”‚
â”‚                                                                     â”‚
â”‚ 2. MySQL performance tuning for high-concurrency OLTP workloads   â”‚
â”‚                                                                     â”‚
â”‚ 3. MongoDB index optimization for aggregation pipeline queries     â”‚
â”‚                                                                     â”‚
â”‚ Refined prompt:                                                    â”‚
â”‚ > PostgreSQL performance optimization techniques for slow queries  â”‚
â”‚   involving multiple table JOINs                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[User can edit the refined prompt or press Enter to accept]
[User presses Enter - switches to Edit Mode with refined prompt]

[dim]Edit Mode â€¢ Shift+Tab: switch to Clarification Mode â€¢ Enter: submit[/dim]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ > PostgreSQL performance optimization techniques for slow queries  â”‚
â”‚   involving multiple table JOINs                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[User presses Enter - submits refined prompt for research]

$ thoth -i --clarify

[dim]Clarification Mode â€¢ Shift+Tab: switch to Edit Mode â€¢ Enter: clarify[/dim]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ >                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[Starts directly in Clarification Mode]
```

---

## 12. Configuration File

### 12.1 Default Configuration

The system works with zero configuration if API keys are in environment variables. The config file at `~/.thoth/config.toml` provides additional control:

```toml
# Thoth Configuration File
version = "2.0"

[general]
default_mode = "default"          # Used when no mode specified (no system prompt)
show_tips = true                  # Show helpful tips for new users
auto_cleanup_days = 90           # Auto-clean operations older than this

[execution]  
poll_interval = 30               # seconds between status checks
max_wait = 30                    # maximum minutes to wait
parallel_providers = true        # run providers simultaneously
adaptive_polling = true          # adjust check intervals dynamically

[output]
combine_reports = false          # create combined report only with --combined flag
format = "markdown"              # output format
timestamp_format = "%Y-%m-%d_%H%M%S"
max_file_size = "100MB"          # maximum input file size

[providers.openai]
api_key = "${OPENAI_API_KEY}"   # reads from environment
model = "o1-deep-research"
temperature = 0.7
max_tokens = 4000
retry_attempts = 3
retry_delay = 1                  # seconds, exponential backoff

[providers.perplexity]
api_key = "${PERPLEXITY_API_KEY}"
model = "sonar-pro"
search_depth = "comprehensive"
academic_mode = false

[providers.mock]
# Mock provider accepts any value as API key for testing
# No configuration required
delay = 2                        # simulated delay in seconds

[cache]
enabled = true
ttl = 3600                      # cache TTL in seconds
max_size = "1GB"

[multi_provider]
fallback_enabled = true
cost_optimization = false
quality_preference = "balanced"
health_check_interval = 300     # seconds
```

### 12.2 Per-Project Configuration (v2.1)

Projects can have their own configuration that overrides the global config:

```toml
# .thoth/config.toml in project directory
[project]
name = "quantum_research"
base_output_dir = "./research"

[providers.openai]
model = "gpt-4-turbo"           # Override for this project

[output]
combine_reports = true          # Always combine for this project
```

### 12.3 Minimal Configuration

For users who want the absolute minimum, Thoth works with just environment variables:

```bash
export OPENAI_API_KEY="sk-..."
export PERPLEXITY_API_KEY="pplx-..."
# That's it - thoth is ready to use
```

---

## 13. Quick Start Guide

### For New Users

1. **Install**: Ensure Python 3.11+ is available
2. **Set API Keys** (optional for testing): 
   ```bash
   # For real usage
   export OPENAI_API_KEY="your-key"
   export PERPLEXITY_API_KEY="your-key"
   
   # For testing
   thoth "test prompt" --provider mock
   ```
3. **Research**: 
   ```bash
   thoth "your research question"
   ```
4. **View Results**: Open the generated `.md` files in current directory

### Common Use Cases

```bash
# Quick technical explanation
thoth "how does HTTPS work"

# API documentation research  
thoth "comprehensive guide to GraphQL"

# Technology comparison
thoth "PostgreSQL vs MySQL for web applications"

# Best practices research
thoth "microservices design patterns"

# Deep technical dive
thoth "internals of Git version control"

# Testing without API keys
thoth "test the tool" --provider mock

# Generate combined report
thoth "distributed systems architecture" --combined

# Clean up old research
thoth clean --days 30

# Check active operations
thoth list --in-progress
```

---

## 14. Error Messages

### User-Friendly Error Handling

All errors go to stderr for proper shell scripting:

```bash
# Missing API keys
$ thoth "quantum computing"
Error: OpenAI API key not found
Please set OPENAI_API_KEY environment variable or run 'thoth init'

# Network issues with retry
$ thoth "distributed systems"
Network error: Unable to reach OpenAI API
Retrying in 2s... (attempt 2/3)
Retrying in 4s... (attempt 3/3)
Error: Failed to connect after 3 attempts

# Long operation
$ thoth "analyze all cloud provider services"
This research may take 15-30 minutes. Consider using --async:
  thoth "analyze all cloud provider services" --async
  
Continue anyway? [Y/n]:

# Invalid provider
$ thoth "test" --provider invalid
Error: Unknown provider: invalid
Valid providers are: openai, perplexity, mock

# Rate limit handling
$ thoth "complex analysis"
Rate limit reached for OpenAI
Waiting 60s before retry...
Falling back to Perplexity provider
```

---

## 15. File Output Structure

### Default Output (Current Directory)

When you run `thoth "your prompt"`, files are created in your current directory:

```
./
â”œâ”€â”€ 2024-08-03_143022_default_openai_your-prompt.md
â””â”€â”€ 2024-08-03_143022_default_perplexity_your-prompt.md

# With --combined flag:
./
â”œâ”€â”€ 2024-08-03_143022_default_openai_your-prompt.md
â”œâ”€â”€ 2024-08-03_143022_default_perplexity_your-query.md
â””â”€â”€ 2024-08-03_143022_default_combined_your-prompt.md
```

### Mock Provider Output

When testing with `--provider mock`:

```
./
â””â”€â”€ 2024-08-03_143022_default_mock_your-prompt.md  # Static test content
```

### Mode Chaining Output (v2.1)

When using `--auto` for mode chaining:

```
./
â”œâ”€â”€ 2024-08-03_143022_clarification_openai_your-prompt.md
â”œâ”€â”€ 2024-08-03_143525_exploration_openai_your-prompt.md
â”œâ”€â”€ 2024-08-03_143525_exploration_perplexity_your-prompt.md
â”œâ”€â”€ 2024-08-03_143525_exploration_combined_your-prompt.md
â”œâ”€â”€ 2024-08-03_144230_deep_research_openai_your-prompt.md
â”œâ”€â”€ 2024-08-03_144230_deep_research_perplexity_your-prompt.md
â””â”€â”€ 2024-08-03_144230_deep_research_combined_your-prompt.md
```

### Example Output File Formats

**Default mode with OpenAI:**
```yaml
---
prompt: What is Python?
mode: default
provider: openai
model: gpt-4o
operation_id: research-20250802-154755-a38d159848984fa8
created_at: 2025-08-02T15:47:55.468596
---

### Prompt

```
What is Python?
```

[Research content follows...]
```

**Deep research mode with system prompt:**
```yaml
---
prompt: explain kubernetes
mode: deep_research
provider: openai
model: gpt-4o
operation_id: research-20250802-154755-a38d159848984fa8
created_at: 2025-08-02T15:47:55.468596
---

### Prompt

```
System: Conduct comprehensive research with citations and multiple perspectives.
Organize findings clearly and highlight key insights.

User: explain kubernetes
```

[Research content follows...]
```

**Mock provider output:**
```yaml
---
prompt: test prompt
mode: default
provider: mock
model: None
operation_id: research-20250802-154755-a38d159848984fa8
created_at: 2025-08-02T15:47:55.468596
---

### Prompt

```
test query
```

[Mock response content...]
```

### File Contents Structure

Each file includes (unless --no-metadata is used):

1. **Metadata header** (YAML front matter, hidden in most Markdown viewers):
   - prompt: The user's research prompt
   - mode: The research mode used
   - provider: The LLM provider used
   - model: The specific model used (e.g., gpt-4o, sonar-pro, None for mock)
   - operation_id: Unique identifier for the operation
   - created_at: Timestamp of creation
   - input_files: List of input files (if any)

2. **Prompt section** (visible in markdown):
   - Shows the exact prompt sent to the LLM
   - For modes with system prompts: displays both system and user prompts
   - For default mode: shows only the user prompt

3. **Research content**:
   - Comprehensive findings
   - Citations and sources (Perplexity)
   - Organized sections and insights
   - Token count and cost estimate (when available)

---

## 16. Advanced Features

While the primary use case is simple, power users can access:

### Mode Selection
- `default` - Direct prompt pass-through (no system prompt) - used when no mode specified
- `thinking` - Quick analysis with system prompt
- `clarification` - Refine questions with system prompt
- `exploration` - Survey options with system prompt
- `deep_research` - Comprehensive research with system prompt

### Provider Selection
- `--provider openai` or `-P openai` - Use only OpenAI
- `--provider perplexity` or `-P perplexity` - Use only Perplexity
- `--provider mock` or `-P mock` - Use mock provider for testing (accepts any API key value)
- Default uses both OpenAI and Perplexity for comprehensive coverage

### Project Organization
- `--project NAME` - Organize outputs in dedicated directories
- Useful for ongoing research topics
- Supports per-project configuration

### Async Operations  
- `--async` - Submit and continue working
- Essential for very long research tasks
- Full checkpoint/resume support

### Mode Chaining (v2.1)
- `--auto` - Automatically use previous output
- Enables workflow: clarification â†’ exploration â†’ deep_research
- Preserves context across modes

### Provider Coordination (v2.1)
- Automatic fallback on provider failure
- Cost-optimized routing (when enabled)
- Health monitoring and circuit breakers
- Cross-provider deduplication

---

## 17. Security and Privacy

- **Local storage only**: All outputs saved locally
- **No telemetry**: No usage tracking or data collection
- **API key protection**: Keys masked in all outputs
- **Secure connections**: HTTPS-only API communication
- **Input validation**: File size limits and path sanitization
- **Checkpoint integrity**: Corruption detection and recovery

---

## 18. Future Enhancements

### Version 2.1
- Smart prompt suggestions based on clarity
- Automatic mode selection based on prompt type
- Research templates for common topics
- Integration with local knowledge bases
- Plugin system for extensibility

### Version 2.2  
- Real-time streaming of research progress
- Web dashboard for operation monitoring
- Export to multiple formats (JSON, CSV)
- Collaborative research sessions
- Batch processing support
- Long operation warnings with async suggestions

---

## 19. Testing Requirements

### Test Suite Status
As of v2.5, the test suite includes:
- **M8T Test Suite**: 10 tests for OpenAI provider achieving **100% pass rate**
  - M8T-01: OpenAI provider initialization with API key
  - M8T-02: OpenAI provider handles missing API key
  - M8T-03: OpenAI provider handles invalid API key
  - M8T-04: OpenAI timeout configuration from CLI
  - M8T-05: OpenAI provider async operation returns job ID
  - M8T-06: OpenAI provider creates output file
  - M8T-07: OpenAI provider with verbose shows configuration
  - M8T-08: OpenAI provider handles rate limit gracefully
  - M8T-09: OpenAI provider with custom config file
  - M8T-10: OpenAI provider handles network timeout
- **Core Test Suite**: 28/28 tests passing when using the mock provider
- **Enhanced Test Infrastructure**: Separate Makefile targets for independent verification

### Mock Provider Behavior
The mock provider is essential for testing and has been fully implemented to:
- Work without any API keys (F-32 requirement satisfied)
- Accept any value as a dummy API key for testing purposes
- Return predictable responses
- Support all provider interface methods
- Simulate realistic delays
- Generate valid output files
- Bypass API key validation when `--provider mock` is specified
- Support mode chaining with --auto

### Error Output Standards
**Important Note**: Rich console library outputs to stdout by design, which is correct behavior for terminal UI libraries. Error messages are properly routed to stderr while UI elements use stdout.

Standards implemented:
- Exit codes follow POSIX conventions (F-35 satisfied)
- Error messages are clear and actionable
- Mode and provider validation happens before API key checks (F-34 satisfied)
- Commands return proper exit codes: 0=success, 1=general error, 2=usage error

### Validation Order
The tool validates in this order (fully implemented):
1. Command structure (missing prompt = exit 2) âœ“
2. Mode validity (invalid mode = exit 1) âœ“
3. Provider validity (invalid provider = exit 1) âœ“
4. API key presence (missing key = exit 1) âœ“
5. API key validity (invalid key = exit 1) âœ“

This ensures users get the most relevant error message first.

### Implementation Details

Key features implemented in v2.5 (OpenAI Provider):
- **AsyncOpenAI Client Integration**: Full async support with httpx timeout configuration
- **Response Storage**: Dictionary-based storage pattern for concurrent operations
- **Timeout Configuration**: Three-level precedence (CLI > config > default)
- **Error Handling**: Comprehensive handling for authentication, rate limits, network errors
- **Retry Logic**: Exponential backoff using tenacity decorator
- **Configuration Support**: model, timeout, temperature, max_tokens from config file
- **CLI Override**: --timeout flag with highest precedence for request timeouts
- **API Key Masking**: All API keys properly masked in output

Key features implemented in v2.1:
- Output directories are created automatically if they don't exist (F-36)
- Init command works with custom config directories via XDG_CONFIG_HOME (F-37)
- Mock provider properly overrides mode-specific provider preferences
- Empty queries are properly validated with appropriate exit codes
- All test patterns updated to match actual output formats
- Combined reports require explicit --combined flag
- Progress display shows elapsed time, next check, and timeout (with implementation status noted)
- Provider flag supports -P short form
- Quiet mode uses -Q flag
- Mode chaining with --auto flag
- Providers command with dynamic model discovery for OpenAI (F-101, F-102)
- Hardcoded model list for Perplexity provider (F-103)
- Provider filtering with --provider flag (F-105)
- Rich table formatting for model display with dynamic column width (F-106)
  - Model ID column width automatically adjusts based on longest model name
  - Ensures model IDs like `gpt-4o-mini-audio-preview-2024-12-17` are never truncated
  - Minimum width of 20 characters for consistent formatting
- Graceful error handling for invalid providers (F-107)
- Note: Due to Click option parsing, providers command requires -- separator: `thoth providers -- --models`
- New commands: update, clean, config, export, import
- Provider fallback and health monitoring
- Adaptive polling intervals
- Shell completion support

### Test Infrastructure Requirements

The test suite requires infrastructure for comprehensive testing:

#### Checkpoint Test Fixtures (M22-01 to M22-05)
- Create test fixtures for checkpoints with different statuses
- Generate aged checkpoints for time-based testing
- Utilities for verifying checkpoint deletion
- Mock checkpoint files with various corruption states
- Test cleanup to prevent test pollution

#### Test Patterns
- Use predictable patterns for test-generated files
- Implement cleanup after each test run
- Support parallel test execution without conflicts

### Manual Testing Requirements

Some features require manual testing due to their interactive or environment-dependent nature:

#### First-Time User Experience (AUDIT-012)
- Manually test the automatic setup wizard for missing API keys
- Verify prompts appear correctly and config is saved
- Test with various combinations of existing/missing environment variables
- Validate that the wizard only appears when needed

#### Network Retry Logic (AUDIT-013)
- Test automatic retry on transient network errors
- Verify retry attempts are properly displayed
- Test timeout behavior on persistent network failures
- Validate error messages for different network conditions

These manual tests should be documented in a separate testing guide and performed before each release.

---

## End of Thoth v2.1 PRD

This specification prioritizes the simplest possible user experience while maintaining all advanced capabilities. The primary innovation is making `thoth "prompt"` the default interaction pattern, removing friction for users who just want quick, comprehensive research results in their current directory.

Key principles:
- **Simple by default**: Just prompt and go
- **Progressive disclosure**: Advanced features available when needed  
- **Current directory convenience**: Results appear where you work
- **Clear communication**: Simple progress and obvious output locations
- **Testability first**: Mock provider enables comprehensive testing

The tool serves both casual users who want instant research and power users who need fine-grained control over the research process.